{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from settings import EXPERIMENTS_DIR\n",
    "from experiment import Experiment\n",
    "from utils import to_device, load_weights, load_embeddings, create_embeddings_matrix\n",
    "from vocab import Vocab\n",
    "from train import create_model\n",
    "from preprocess import load_dataset, create_dataset_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'train.0d1b9t6u'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment.load(EXPERIMENTS_DIR, exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(model_class=<class 'models.Seq2SeqMeaningStyle'>, preprocess_exp_id='preprocess.pb25misv', embedding_size=300, hidden_size=256, dropout=0.2, scheduled_sampling_ratio=0.5, pretrained_embeddings=True, trainable_embeddings=False, meaning_size=32, style_size=32, lr=0.001, weight_decay=1e-07, grad_clipping=5, D_num_iterations=10, D_loss_multiplier=1, P_loss_multiplier=10, P_bow_loss_multiplier=1, use_discriminator=True, use_predictor=False, use_predictor_bow=True, use_motivator=True, use_gauss=False, num_epochs=5, batch_size=256, best_loss='loss')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 21176, val: 10000, test: 10000\n",
      "Vocab: 28106, style vocab: 2\n",
      "W_emb: (28106, 300)\n"
     ]
    }
   ],
   "source": [
    "preprocess_exp = Experiment.load(EXPERIMENTS_DIR, exp.config.preprocess_exp_id)\n",
    "dataset_train, dataset_val, dataset_test, vocab, style_vocab, W_emb = load_dataset(preprocess_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/josephcappadona/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "dataset_reader = create_dataset_reader(preprocess_exp.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(exp.config, vocab, style_vocab, dataset_train.max_len, W_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(model, exp.experiment_dir.joinpath('best.th'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(instances):\n",
    "    if not isinstance(instances, list):\n",
    "        instances = [instances,]\n",
    "        \n",
    "    if not isinstance(instances[0], dict):\n",
    "        sentences = [\n",
    "            dataset_reader.preprocess_sentence(dataset_reader.spacy( dataset_reader.clean_sentence(sent)))\n",
    "            for sent in instances\n",
    "        ]\n",
    "        \n",
    "        style = list(style_vocab.token2id.keys())[0]\n",
    "        instances = [\n",
    "            {\n",
    "                'sentence': sent,\n",
    "                'style': style,\n",
    "            }\n",
    "            for sent in sentences\n",
    "        ]\n",
    "        \n",
    "        for inst in instances:\n",
    "            inst_encoded = dataset_train.encode_instance(inst)\n",
    "            inst.update(inst_encoded)            \n",
    "    \n",
    "    \n",
    "    instances = [\n",
    "        {\n",
    "            'sentence': inst['sentence_enc'],\n",
    "            'style': inst['style_enc'],\n",
    "        } \n",
    "        for inst in instances\n",
    "    ]\n",
    "    \n",
    "    instances = default_collate(instances)\n",
    "    instances = to_device(instances)      \n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(outputs):\n",
    "    predicted_indices = outputs[\"predictions\"]\n",
    "    end_idx = vocab[Vocab.END_TOKEN]\n",
    "    \n",
    "    if not isinstance(predicted_indices, np.ndarray):\n",
    "        predicted_indices = predicted_indices.detach().cpu().numpy()\n",
    "\n",
    "    all_predicted_tokens = []\n",
    "    for indices in predicted_indices:\n",
    "        indices = list(indices)\n",
    "\n",
    "        # Collect indices till the first end_symbol\n",
    "        if end_idx in indices:\n",
    "            indices = indices[:indices.index(end_idx)]\n",
    "\n",
    "        predicted_tokens = [vocab.id2token[x] for x in indices]\n",
    "        all_predicted_tokens.append(predicted_tokens)\n",
    "        \n",
    "    return all_predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  ' '.join(dataset_val.instances[1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'during the period of industrial growth from 1850 to 1950 , detroit ’s population grew dramatically .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = create_inputs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the the the the the the the the the the the the the the the the the the the the'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_styles = list(style_vocab.token2id.keys()) #['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kids', 'scholars']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences0 = [s for s in dataset_val.instances if s['style'] == possible_styles[0]]\n",
    "sentences1 = [s for s in dataset_val.instances if s['style'] == possible_styles[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2855 this means that in the extreme north and south , most winds and currents run eastward , while near\n",
      "470 the west indies is a group of islands that stretches from near the u.s. state of florida to the\n",
      "1466 factories in the metropolitan area produce metals , chemicals , and machinery .\n",
      "5709 fewer than one - quarter of the islands are populated .\n",
      "1175 nearly everyone is muslim .\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences0)), 5):\n",
    "    print(i, ' '.join(sentences0[i]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 it had two lenses of identical focal length — one transmitting the image to the film and the other\n",
      "354 after starring in neiboku sendai hagi ( “ the disputed succession ” ) , he adopted the dynastic name\n",
      "2014 highsmith , who took her stepfather ’s name , graduated from barnard college , new york city , in\n",
      "1322 cugat ’s bands included violins , maracas , and bongo and conga drums and featured dancers who demonstrated the\n",
      "1725 caliban , a feral , sullen , misshapen creature in shakespeare ’s the tempest .\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences1)), 5):\n",
    "    print(i, ' '.join(sentences1[i]['sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = 2855 # np.random.choice(np.arange(len(sentences0)))\n",
    "target1 = 804 # np.random.choice(np.arange(len(sentences0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this means that in the extreme north and south , most winds and currents run eastward , while near\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences0[target0]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most employment is related to the gaming and tourist industry .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences1[target1]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = create_inputs([\n",
    "    sentences0[target0],\n",
    "    sentences1[target1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['style_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['meaning_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_decoded = model.decode(z_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = get_sentences(original_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the the the the the the the the the the the the the the the the the the the\n",
      "the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden_swapped = {\n",
    "    'meaning_hidden': torch.stack([\n",
    "        z_hidden['meaning_hidden'][0].clone(),\n",
    "        z_hidden['meaning_hidden'][1].clone(),        \n",
    "    ], dim=0),\n",
    "    'style_hidden': torch.stack([\n",
    "        z_hidden['style_hidden'][1].clone(),\n",
    "        z_hidden['style_hidden'][0].clone(),        \n",
    "    ], dim=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_decoded = model.decode(z_hidden_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_sentences = get_sentences(swaped_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rice had hard things in it .\n",
      "which is awesome !\n",
      "\n",
      "plus is really hard to it .\n",
      "the rice was awesome .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))\n",
    "print()\n",
    "print(' '.join(swaped_sentences[0]))\n",
    "print(' '.join(swaped_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
